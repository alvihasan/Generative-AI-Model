{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMERl+PQCrXESb8WGCZeq0d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAmlIHDXxCHK","executionInfo":{"status":"ok","timestamp":1727775572455,"user_tz":-360,"elapsed":11929,"user":{"displayName":"Md. Ashraful Islam","userId":"10804497249634088005"}},"outputId":"6d4c0a37-0f3f-42de-bdbc-8052df28c339"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/106.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -qU groq"]},{"cell_type":"code","source":["import os\n","import getpass\n","from groq import Groq"],"metadata":{"id":"FrEEKyS7xQX4","executionInfo":{"status":"ok","timestamp":1727775587620,"user_tz":-360,"elapsed":1362,"user":{"displayName":"Md. Ashraful Islam","userId":"10804497249634088005"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["os.environ[\"GROQ_API_KEY\"] = getpass.getpass()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wgi8tRdNxT0C","executionInfo":{"status":"ok","timestamp":1727775593630,"user_tz":-360,"elapsed":4122,"user":{"displayName":"Md. Ashraful Islam","userId":"10804497249634088005"}},"outputId":"83a5c438-eb2f-4492-e0bf-eb1e1e0e85d7"},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}]},{"cell_type":"code","source":["client = Groq(\n","    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",")"],"metadata":{"id":"sMWjhlOGy4cA","executionInfo":{"status":"ok","timestamp":1727775597637,"user_tz":-360,"elapsed":682,"user":{"displayName":"Md. Ashraful Islam","userId":"10804497249634088005"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["chat_completion = client.chat.completions.create(\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"Explain the importance of large language models\",\n","        }\n","    ],\n","    model=\"llama3-8b-8192\",\n",")\n","\n","print(chat_completion.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C_QBqAUKxqvg","executionInfo":{"status":"ok","timestamp":1727775704875,"user_tz":-360,"elapsed":1271,"user":{"displayName":"Md. Ashraful Islam","userId":"10804497249634088005"}},"outputId":"d558fcdf-e8c3-4b34-a613-df900ce58df1"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Large language models (LLMs) are AI models designed to process and comprehend human language, enabling applications such as natural language processing (NLP), machine translation, and text classification. The importance of LLMs lies in their ability to improve human-computer interaction, facilitate language-based tasks, and drive technological advancements in various fields. Here are the key reasons why LLMs are significant:\n","\n","1. **Improved NLP capabilities**: LLMs enable AI systems to better understand and generate human language, which is critical for applications like chatbots, virtual assistants, and language translation.\n","2. **Enhanced text analysis**: LLMs can analyze and extract insights from large volumes of text data, including sentiment analysis, entity recognition, and topic modeling.\n","3. **Applications in various industries**: LLMs are being used in industries such as healthcare (e.g., medical transcription, clinical trials), finance (e.g., text analysis for risk assessment), and education (e.g., personalized learning, language learning).\n","4. **Advancements in conversational AI**: LLMs enable conversational AI systems to engage in more natural and human-like conversations, improving user experiences in voice assistants, customer service, and other applications.\n","5. **Improved search and recommendations**: LLMs can analyze text data to improve search engine rankings, content recommendation systems, and personalized advertising.\n","6. **Research and development**: LLMs serve as benchmarks for evaluating NLP capabilities, driving innovation and advancements in AI research and development.\n","7. **Scalability and efficiency**: LLMs can process and analyze large volumes of text data efficiently, making them ideal for applications where scale and speed are crucial.\n","8. **Supporting multilingual communication**: LLMs can be trained on multiple languages, enabling cross-cultural communication and facilitating international collaboration.\n","9. **Facilitating language learning**: LLMs can assist language learners by providing personalized feedback, correcting errors, and suggesting vocabulary and grammar improvements.\n","10. **Potentially solving common AI challenges**: LLMs can help address challenges like common-sense reasoning, ambiguity, and context-dependent understanding, which are crucial for AI systems to tackle complex tasks.\n","11. **Advancing artificial general intelligence**: LLMs are a key component in the development of artificial general intelligence (AGI), as they demonstrate the ability to process and understand human language, a crucial aspect of human intelligence.\n","12. **Driving business innovation**: LLMs can help businesses innovate and improve processes, such as customer service, marketing, and product development, by analyzing and generating text-based data.\n","\n","In summary, large language models play a vital role in revolutionizing the way humans interact with computers and enabling AI systems to process and understand human language. Their applications span various industries, and their impact will continue to shape the future of AI, NLP, and human-computer interaction.\n"]}]},{"cell_type":"code","source":["stream = client.chat.completions.create(\n","    messages=[\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"Explain the importance of large language models\",\n","        }\n","    ],\n","    model=\"llama3-8b-8192\",\n","    stream=True\n",")\n","\n","# Print the incremental deltas returned by the LLM.\n","for chunk in stream:\n","    print(chunk.choices[0].delta.content, end=\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fgh_nveldWEN","executionInfo":{"status":"ok","timestamp":1727775843422,"user_tz":-360,"elapsed":1390,"user":{"displayName":"Md. Ashraful Islam","userId":"10804497249634088005"}},"outputId":"04b386a1-40e3-4fee-e05a-611a393b5894"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Large language models, also known as LLMs, have revolutionized the field of natural language processing (NLP) and have numerous significant implications for various industries and aspects of society. Here are some of the key importance of large language models:\n","\n","1. **Improved Language Understanding**: LLMs are trained on vast amounts of text data and can learn to understand human language in a more nuanced and complex way. This leads to better performance on tasks like language translation, sentiment analysis, and question answering.\n","\n","2. **Enhanced Question Answering**: LLMs can process and comprehend natural language queries, allowing them to answer questions accurately and generate relevant responses. This technology has applications in customer service, personal assistants, and educational platforms.\n","\n","3. **Multilingual Capabilities**: LLMs can handle multiple languages, making it easier for people to communicate across language barriers. This has significant implications for international business and global communication.\n","\n","4. **Content Generation**: LLMs can generate coherent and context-based text, enabling applications like automatic news writing, summarization, and even creative writing.\n","\n","5. **Improved Human-Computer Interaction**: LLMs can engage users in natural language conversations, allowing for more intuitive and user-friendly interfaces. This can lead to increased adoption and better experiences with technologies like virtual assistants and chatbots.\n","\n","6. **Enhanced Research and Discovery**: LLMs can aid researchers in processing and analyzing large amounts of text data from scientific papers, literature, and other sources. This accelerates the discovery process and unlocks new insights in fields like medicine, climate science, and social sciences.\n","\n","7. **Personalized Recommendations**: LLMs can analyze user behavior and preferences to generate personalized content, product recommendations, and even music playlists.\n","\n","8. **Improved Task Automation**: LLMs can automate repetitive and mundane tasks like data entry, document processing, and customer support, freeing up human resources for more strategic and creative work.\n","\n","9. **Language Preservation**: LLMs can help preserve endangered languages by creating digital language archives and engaging native speakers in language learning and preservation efforts.\n","\n","10. **New Business Models**: LLMs have given rise to new business opportunities in areas like language processing services, content generation, and personalized recommendations.\n","\n","11. **Potential to Transform Industries**: The capabilities of LLMs have the potential to transform industries like healthcare, finance, and education, by enabling more accurate diagnosis, financial forecasting, and personalized learning.\n","\n","12. **Potential for Societal Impact**: LLMs have the potential to improve accessibility for people with disabilities, enhance language learning for non-native speakers, and even create new forms of art and entertainment.\n","\n","In summary, large language models have the potential to revolutionize various aspects of society, from language understanding and generation to task automation and new business opportunities.None"]}]},{"cell_type":"code","source":["\"\"\"\n","Performing a basic Chat Completion\n","\"\"\"\n","\n","chat_completion = client.chat.completions.create(\n","    #\n","    # Required parameters\n","    #\n","    messages=[\n","        # Set an optional system message. This sets the behavior of the\n","        # assistant and can be used to provide specific instructions for\n","        # how it should behave throughout the conversation.\n","        {\n","            \"role\": \"system\",\n","            \"content\": \"you are a helpful assistant.\"\n","        },\n","        # Set a user message for the assistant to respond to.\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"Explain the importance of fast language models\",\n","        }\n","    ],\n","\n","    # The language model which will generate the completion.\n","    model=\"llama3-8b-8192\",\n","\n","    #\n","    # Optional parameters\n","    #\n","\n","    # Controls randomness: lowering results in less random completions.\n","    # As the temperature approaches zero, the model will become deterministic\n","    # and repetitive.\n","    temperature=0.5,\n","\n","    # The maximum number of tokens to generate. Requests can use up to\n","    # 32,768 tokens shared between prompt and completion.\n","    max_tokens=1024,\n","\n","    # Controls diversity via nucleus sampling: 0.5 means half of all\n","    # likelihood-weighted options are considered.\n","    top_p=1,\n","\n","    # A stop sequence is a predefined or user-specified text string that\n","    # signals an AI to stop generating content, ensuring its responses\n","    # remain focused and concise. Examples include punctuation marks and\n","    # markers like \"[end]\".\n","    stop=None,\n","\n","    # If set, partial message deltas will be sent.\n","    stream=False,\n",")\n","\n","# Print the completion returned by the LLM.\n","print(chat_completion.choices[0].message.content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AjKAOviyh1S","executionInfo":{"status":"ok","timestamp":1727764616086,"user_tz":-360,"elapsed":4703,"user":{"displayName":"Md. Ashraful Islam","userId":"10804497249634088005"}},"outputId":"012bfbd1-9cd7-41f5-f59d-871a351e7b47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fast language models have gained significant attention in recent years due to their ability to process and generate human-like language quickly and efficiently. Here are some reasons why fast language models are important:\n","\n","1. **Real-time Applications**: Fast language models can be used in real-time applications such as chatbots, virtual assistants, and language translation software. They can quickly respond to user queries, making interactions more seamless and efficient.\n","2. **Large-Scale Data Processing**: Fast language models can handle large volumes of data, making them suitable for applications that require processing and analyzing massive amounts of text data, such as social media monitoring, sentiment analysis, and text classification.\n","3. **Improved User Experience**: By providing fast and accurate responses, fast language models can enhance the user experience in various applications, such as search engines, recommendation systems, and language translation tools.\n","4. **Enhanced Conversational AI**: Fast language models can be used to power conversational AI systems, enabling them to engage in more natural and human-like conversations. This can lead to more effective customer service, improved user engagement, and increased customer satisfaction.\n","5. **Scalability**: Fast language models can be easily scaled up to handle large volumes of traffic and requests, making them suitable for applications that require high availability and reliability.\n","6. **Cost-Effective**: Fast language models can reduce the computational resources required for language processing tasks, making them a cost-effective solution for applications that require large-scale language processing.\n","7. **Advancements in NLP**: Fast language models have driven advancements in Natural Language Processing (NLP) research, enabling the development of more sophisticated language models, and improving the accuracy and efficiency of NLP applications.\n","8. **Improved Accessibility**: Fast language models can be used to improve accessibility for people with disabilities, such as those who rely on screen readers or other assistive technologies.\n","9. **Enhanced Language Understanding**: Fast language models can be used to improve language understanding by analyzing and processing large amounts of text data, enabling the development of more accurate language models and improving the overall performance of NLP applications.\n","10. **Future of Language Processing**: Fast language models are a key component of the future of language processing, enabling the development of more sophisticated language models, and paving the way for more advanced applications in areas such as language translation, sentiment analysis, and text summarization.\n","\n","In summary, fast language models are important because they enable real-time language processing, improve user experience, enhance conversational AI, and drive advancements in NLP research, among other benefits.\n"]}]},{"cell_type":"code","source":["\"\"\"\n","Streaming a Chat Completion\n","To stream a completion, simply set the parameter stream=True.\n","Then the completion function will return an iterator of completion deltas rather than a single, full completion.\n","\"\"\"\n","\n","stream = client.chat.completions.create(\n","    #\n","    # Required parameters\n","    #\n","    messages=[\n","        # Set an optional system message. This sets the behavior of the\n","        # assistant and can be used to provide specific instructions for\n","        # how it should behave throughout the conversation.\n","        {\n","            \"role\": \"system\",\n","            \"content\": \"you are a helpful assistant.\"\n","        },\n","        # Set a user message for the assistant to respond to.\n","        {\n","            \"role\": \"user\",\n","            \"content\": \"Explain the importance of fast language models\",\n","        }\n","    ],\n","\n","    # The language model which will generate the completion.\n","    model=\"llama3-8b-8192\",\n","\n","    #\n","    # Optional parameters\n","    #\n","\n","    # Controls randomness: lowering results in less random completions.\n","    # As the temperature approaches zero, the model will become deterministic\n","    # and repetitive.\n","    temperature=0.5,\n","\n","    # The maximum number of tokens to generate. Requests can use up to\n","    # 2048 tokens shared between prompt and completion.\n","    max_tokens=1024,\n","\n","    # Controls diversity via nucleus sampling: 0.5 means half of all\n","    # likelihood-weighted options are considered.\n","    top_p=1,\n","\n","    # A stop sequence is a predefined or user-specified text string that\n","    # signals an AI to stop generating content, ensuring its responses\n","    # remain focused and concise. Examples include punctuation marks and\n","    # markers like \"[end]\".\n","    stop=None,\n","\n","    # If set, partial message deltas will be sent.\n","    stream=True,\n",")\n","\n","# Print the incremental deltas returned by the LLM.\n","for chunk in stream:\n","    print(chunk.choices[0].delta.content, end=\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0pqJggNyjQj","executionInfo":{"status":"ok","timestamp":1727764635450,"user_tz":-360,"elapsed":3766,"user":{"displayName":"Md. Ashraful Islam","userId":"10804497249634088005"}},"outputId":"e42353f5-84b6-498d-a913-135f23744cf9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fast language models, also known as efficient language models, have gained significant importance in recent years due to their ability to process and generate human-like language at scale, while being computationally efficient. Here are some reasons why fast language models are important:\n","\n","1. **Scalability**: Fast language models can process large amounts of text data quickly, making them ideal for applications where speed and efficiency are crucial. This is particularly important in industries like customer service, where timely responses are essential.\n","2. **Real-time processing**: Fast language models can process text in real-time, enabling applications like chatbots, voice assistants, and language translation services to respond quickly and accurately.\n","3. **Low-latency**: Fast language models can reduce the latency associated with language processing, which is critical for applications like speech recognition, language translation, and text-to-speech synthesis.\n","4. **Cost-effective**: Fast language models can be trained on smaller datasets and require less computational resources, making them more cost-effective than traditional language models.\n","5. **Improved user experience**: Fast language models can enable more natural and conversational interactions between humans and machines, leading to a better user experience.\n","6. **Enhanced AI capabilities**: Fast language models can be used as building blocks for more advanced AI applications, such as natural language processing, sentiment analysis, and text summarization.\n","7. **Support for edge computing**: Fast language models can be deployed on edge devices, such as smartphones and smart home devices, enabling real-time language processing and analysis at the edge.\n","8. **Improved language understanding**: Fast language models can be fine-tuned for specific domains and tasks, leading to improved language understanding and more accurate text classification.\n","9. **Increased accessibility**: Fast language models can be used to develop language processing tools for under-resourced languages, making it easier for people to communicate and access information in their native languages.\n","10. **Research and development**: Fast language models can accelerate research in natural language processing and AI, enabling scientists and developers to explore new ideas and applications more quickly.\n","\n","Some examples of fast language models include:\n","\n","* BERT (Bidirectional Encoder Representations from Transformers)\n","* RoBERTa (Robustly Optimized BERT Pretraining Approach)\n","* DistilBERT (Distilled BERT)\n","* T5 (Text-to-Text Transformer)\n","* XLNet (eXtra Large Language Model)\n","\n","These models have been designed to be more efficient and scalable, while still maintaining high levels of accuracy and performance.None"]}]}]}